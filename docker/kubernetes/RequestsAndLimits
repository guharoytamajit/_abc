Requests and Limits:

Requests in partucular are very important if we want a well behaved cluster.
In pods  or Deployment we can define requests and limit like this:

apiVersion: v1
kind: Pod
metadata:
  name: demo
spec:
  containers:
  - name: demo1
  image: demo/demo1
  resources:
    requests:
      memory: "16Mi"
      cpu: "100m"
    limits:
      memory: "32Mi"
      cpu: "200m"
  - name: demo2
  image: demo/demo2
  resources:
    requests:
      memory: "64Mi"
      cpu: "200m"
    limits:
      memory: "128Mi"
      cpu: "400m"


 ---------------
Requests and Limits are actually specified inside container definition and they are feature of container not pod
---------------------------
Requests:
 Amount of resources "we think" each Container would require.During execution it may not comsume that much. 
If request value not provided by defualt 0 memory and cpu requests will be considered.
So even if actual resource consumption is more than requested resources, pods will continue to run if resource is available.
Requests value is only important to resource scheduler,if requested resource of pod is not available in any node,then pod will be in pending state("kubectl get pods") instead of running.
We should not over estimate this request resources values otherwise even if resource is available in node, additional pods will be in pending state or not scheduled(because total request limit exceeds node capacity  ) 
if we do "kubectl describe pod <pending pod name>" in pending pod, in event section we will see "Failed Scheduling" with reason

cpu: "200m"     =>  200 mill core or .2 core (cpu: .2)
memory: "32Mi"  =>  32*1024 Ki(kilo-bytes)            

Note:
1Mi=1024Ki=1024*1024 bytes 
1M=1000K=1000*1000 bytes
if you specify just number without any unit in memory then it will be considered bytes eg. memory: "1000000"

What is the advantage of defining requests resource?
Resource scheduler will look into this and schedule the pod in a node which has enougn resource to run.



>kubectl get nodes #get list of node names
>kubectl describe node <node name>
It will show all details of node like:
Capacity,allocatable,list of pods running in this node and their requests and limits,Total cpu requests,Total cpu limits,Total memory requests,Total memory limits,events etc

------------------------

Limits:
If the actual memory usage of the container at run time exceeds the limit defined,then container will be killed(pod will still remain there,container will attempt to restart)
If the actual CPU usage of the container at run time exceeds the limit,then container will continue to run but the CPU will be clamped(ie. cpu will not be allowed to go over the limit)

Memory Limits can be very useful to prevent memory leak
=========================

Keep Limits >= Requests 
Main purpose of Requests and Limits to give signals to scheduler. 
========================

Quality of service(QOS) and Eviction: 

Schudeler:
distributes load(pods) across nodes,it tries to distribute load proportionally among nodes.

QOS:
if every container in a pod has a defined "request" and "limit" and their values are same, it will be tagged as "QoS:Guaranteed"
if every container in a pod specifies a "request" but no "limit",it will be tagges as "QoS:Burstable".
if every container in a pod does not define "request" and "limit",it will be tagges as "QoS:BestEffort".

We can view QoS label of a pod as:
>kubectl describe pod <name>

QoS label decides which pod to evict if node is under pressure/resource shortage.

Scheduler will evict "QoS:BestEffort" pods first to free resources,if that is not enough it will start evecting "QoS:Burstable".
Eviction doesnt mean pod will be terminated for ever,it is basically rescheduled.

Priority:Higher value more priority

example:
In a Node of 900mb capacity,one pod of  "QoS:Guaranteed" type with memory 500mb and priority:5 is running.
Now  a new pos of  "QoS:Guaranteed" type with memory 500mb and priority:10 is scheduled.
1st pod will be evicted because although both have "QoS:Guaranteed" type,but 2nd pod has higher priority. 

 
==============================================================
NodeSelector: 
schedule pod to a specific node(or subset of nodes) in cluster:
helps to target a specific set of nodes for pod scheduling
this is achieved by assigning few labels on node eg disktype=ssd,cputype=gpu,gpu-present=true
This concept is very useful we can schedule high priority pods in the node which has better hardware.

We can attach label using "kubectl label" command
To attach label to a node:
>kubectl label node node1 disktype=fast
>kubectl get node node1 --show-labels

We configure nodeSelector inside spec of deployment
====deployment.yaml====
apiVersion: apps/v1
kind: Deployment
metadata:
  name: streamer-v4-deployment
  labels:
    app: streamer-v4
spec:
  replicas: 2
  selector:
    matchLabels:
      app: streamer-v4
  template:
    metadata:
      labels:
        app: streamer-v4
    spec:
      containers:
      - name: streamer-v4
        image: coolregistryusa.biz/jmarhee/streamer-v4
        ports:
        - containerPort: 8880
      nodeSelector:
        disktype: "fast"
		
>kubectl apply -f .       #deployment deployed
>kubectl get pod -o wide  #here you will see pods will be deployed in node with label 	 disktype: "fast"	
---------------
Using NodeSelectors in Kubernetes is a common practice to influence scheduling decisions, which determine on which node (or group of nodes) a pod should be run. 
NodeSelectors are based on key-value pairs as labels. Common use cases include:

1)Dedicate nodes to certain teams or customers (multi-tenancy)
2)Distinguish between different types of nodes (“expensive” nodes with specialized hardware, e.g. GPUs and FPGAs, or resources, ephemeral “spot” instances)
3)Define topologies for rack/zone/region awareness and high-availability

---------------------
NodeSelector VS PodNodeSelector
NodeSelector: depending upon NodeSelector label,pod or deployment ends up in a subset of worker nodes.
PodNodeSelector: depending upon pod or deployment namespaces they ends up in a subset of worker nodes(actually it injects NodeSelector labes in pods 
which can be confirmed by "kubectl desc pods").

----------------------
PodNodeSelector:

When we deploy a pod(or deploy,Daemonset etc) to a namespace eg. dev,test,prod it should be scheduled in a subset of worker nodes(identified by labels)
We dont have to declare NodeSelector.
prod worker node set can have better hardware quality than test worker-node set.

Now, you can specify scheduler.alpha.kubernetes.io/node-selector option in annotations for your namespace, example:

apiVersion: v1
kind: Namespace
metadata
 name: ns1
 annotations:
   scheduler.alpha.kubernetes.io/node-selector: env=test
spec: {}
status: {}

After these steps, all the pods created in this namespace will have this section automatically added:

nodeSelector
  env: test
  
We also need to label our worker nodes as per our requirements: 
kubectl label node <yournode> env=test 


For PodNodeSelector to work we have to enable admission control plugin.
Inside master node we have to edit kube-apiserver.yaml (/etc/kubernetes/manifests/kube-apiserver.yaml)
update spec,add PodNodeSelector in enable-admission-plugins as shown below:

spec:
  containers:
  - command"
    - kube-apiserver
	- --enable-admission-plugins=NodeRestriction,PodNodeSelector 

After saved it will restsrt kube-apiserver pod in kube-system namespace.

===================================================================================================

Init Containers:
As we know a pod can have one or more containers
Init-containers is the container that runs(like a job it completes) before the actual containers starts
We can have multiple init containers,ther run sequentially one after the another,finally actual container starts.
If any of the init container fails it wont proceed by creating the actual container,instead pod will be restarted and the same cycle continues.
If you set restart policy of pod to "never",it will not be restarted on any init container failure.
example:
init container may checkout source code and build artifact and save it in a volume
then actual container starts and use that artifact to run.

example:
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: ic-deploy
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: ic
    spec:
      initContainers:
      - name: msginit
        image: centos:7
        command:
        - "bin/bash"
        - "-c"
        - "echo INIT_DONE > /ic/this"
        volumeMounts:
        - mountPath: /ic
          name: msg
      containers:
      - name: main
        image: centos:7
        command:
        - "bin/bash"
        - "-c"
        - "while true; do cat /ic/this; sleep 5; done"
        volumeMounts:
        - mountPath: /ic
          name: msg
      volumes:
      - name: msg
        emptyDir: {}










