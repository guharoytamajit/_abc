
Scenario1:
>kubectl apply -f deployment_aks.yaml

>kubectl get deploy,po,pvc,pv
NAME                           READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nginx-deploy   2/2     2            2           7m22s

NAME                                READY   STATUS    RESTARTS   AGE
pod/nginx-deploy-57b4c9cf5f-nnkvd   1/1     Running   0          7m22s
pod/nginx-deploy-57b4c9cf5f-v29jw   1/1     Running   0          7m22s

NAME                                       STATUS   VOLUME                                                  CAPACITY   ACCESS-MODES   STORAGECLASS   AGE
persistentvolumeclaim/mypvc   Bound    pvc-91e673d8-a6e1-4ad7-9b9c-7eb4168a9817   2Gi           RWX                       azurefile               7m22s

NAME                                                                                  CAPACITY   ACCESS-MODES   RECLAIM POLICY   STATUS     CLAIM                STORAGECLASS   REASON   AGE
persistentvolume/pvc-91e673d8-a6e1-4ad7-9b9c-7eb4168a9817   2Gi        RWX                      Delete                     Bound       default/mypvc         azurefile                  " "         7m1s


From any pod if we all we andd any file in location /usr/share/nginx/html, it is also visible from the other pod in same location.


Lets try to delete PV
>kubectl delete persistentvolume/pvc-91e673d8-a6e1-4ad7-9b9c-7eb4168a9817
>kubectl get pv

NAME                                                                                    CAPACITY   ACCESS-MODES   RECLAIM POLICY   STATUS        CLAIM           STORAGECLASS   REASON   AGE
persistentvolume/pvc-91e673d8-a6e1-4ad7-9b9c-7eb4168a9817   2Gi          RWX                      Delete                    Terminating   default/mypvc   azurefile                               15m

pvc will keep on showing "terminating" but it will not be terminated as it is getting used by pods,and pvc.

Even if we delete delete deploy still pv is there as pvc is holding it.
>kubectl delete deployment.apps/nginx-deploy


kubectl get deploy,po,pvc,pv
NAME                                     STATUS   VOLUME                                                        CAPACITY   ACCESS-MODES   STORAGECLASS   AGE
persistentvolumeclaim/mypvc   Bound      pvc-91e673d8-a6e1-4ad7-9b9c-7eb4168a9817   2Gi             RWX                       azurefile                27m

NAME                                                                                     CAPACITY   ACCESS-MODES   RECLAIM POLICY   STATUS        CLAIM           STORAGECLASS   REASON   AGE
persistentvolume/pvc-91e673d8-a6e1-4ad7-9b9c-7eb4168a9817   2Gi           RWX                      Delete                     Terminating   default/mypvc   azurefile               27m

Now if we delete pvc both pvc and pv will be deleted:
>kubectl delete persistentvolumeclaim/mypvc
persistentvolumeclaim "mypvc" deleted

>kubectl get deploy,po,pvc,pv              
No resources found in default namespace.

The file share correspending to volume is also deleted as it was created sing kubernetes
==========================================================================
Scenario2:
>kubectl apply -f deployment_aks.yaml

>kubectl get deploy,po,pvc,pv
NAME                           READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nginx-deploy   2/2     2            2           107s

NAME                                READY   STATUS    RESTARTS   AGE
pod/nginx-deploy-57b4c9cf5f-j6mt4   1/1     Running   0          108s
pod/nginx-deploy-57b4c9cf5f-zt9g9   1/1     Running   0          108s

NAME                                    STATUS   VOLUME                                                     CAPACITY   ACCESS-MODES   STORAGECLASS   AGE
persistentvolumeclaim/mypvc   Bound    pvc-961d8174-572e-4f35-a72d-dd1cb9d0774c   2Gi            RWX                        azurefile             107s

NAME                                                                                       CAPACITY   ACCESS-MODES   RECLAIM POLICY   STATUS   CLAIM           STORAGECLASS   REASON   AGE
persistentvolume/pvc-961d8174-572e-4f35-a72d-dd1cb9d0774c   2Gi                RWX                    Delete                    Bound    default/mypvc   azurefile                                   106s


>kubectl  delete  persistentvolumeclaim/mypvc
persistentvolumeclaim "mypvc" deleted

>kubectl get pv,pvc                                 
NAME                                                                                     CAPACITY   ACCESS-MODES   RECLAIM POLICY   STATUS   CLAIM           STORAGECLASS   REASON   AGE
persistentvolume/pvc-961d8174-572e-4f35-a72d-dd1cb9d0774c   2Gi            RWX                      Delete                     Bound    default/mypvc   azurefile                                4m20s

NAME                                      STATUS        VOLUME                                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/mypvc   Terminating   pvc-961d8174-572e-4f35-a72d-dd1cb9d0774c   2Gi           RWX                          azurefile             4m21s

Now pvc is in terminating state ,but it will not be deleted as pods are using it.

Now lets delete deployment.
>kubectl delete deployment.apps/nginx-deploy
deployment.apps "nginx-deploy" deleted


Once deployment is deleted not only PVC but PV also get deleted because PV has RECLAIM POLICY  of  Delete.
>kubectl get deploy,po,pvc,pv               
No resources found in default namespace.

If  PV had "Retain" reclaim policy, if a user deletes a PersistentVolumeClaim, the corresponding PersistentVolume is not be deleted. Instead, it is moved to the Released phase, where all of its data can be manually recovered

We can change the reclaim policy of pv as:
change reclaim policy 
 >kubectl patch pv <your-pv-name> -p '{"spec":{"persistentVolumeReclaimPolicy":"Retain"}}'
 
 
 ====================================================
 Scenario3:
>kubectl apply -f deployment_aks.yaml

kubectl get deploy,po,pvc,pv
NAME                                     READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nginx-deploy   2/2           2                        2             58s

NAME                                READY   STATUS    RESTARTS   AGE
pod/nginx-deploy-57b4c9cf5f-cr5jj   1/1     Running   0          58s
pod/nginx-deploy-57b4c9cf5f-s2zmx   1/1     Running   0          58s

NAME                                    STATUS   VOLUME                                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/mypvc   Bound    pvc-5b6c7546-8746-4942-9522-6364e060ad4e   2Gi           RWX                         azurefile             58s

NAME                                                                                     CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM             STORAGECLASS   REASON   AGE
persistentvolume/pvc-5b6c7546-8746-4942-9522-6364e060ad4e   2Gi           RWX                      Delete                     Bound      default/mypvc   azurefile                                 57s


Lets change RECLAIM POLICY of PV so that if we delete PVC ,PV retains
>kubectl patch pv pvc-5b6c7546-8746-4942-9522-6364e060ad4e  -p '{"spec":{"persistentVolumeReclaimPolicy":"Retain"}}'

>kubectl get pv                                                                                                     
NAME                                                             CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM           STORAGECLASS   REASON   AGE
pvc-5b6c7546-8746-4942-9522-6364e060ad4e   2Gi             RWX                      Retain                     Bound    default/mypvc   azurefile                                 3m46s


Now suppose we accidentally delete pv
>kubectl  delete  pv pvc-5b6c7546-8746-4942-9522-6364e060ad4e

>kubectl get pv
NAME                                                                                     CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS        CLAIM           STORAGECLASS   REASON   AGE
persistentvolume/pvc-5b6c7546-8746-4942-9522-6364e060ad4e   2Gi          RWX                      Retain                    Terminating   default/mypvc   azurefile                                  6m4s


since it is used by PVC and pods it will not be deleted and it will remain in terminating state until pods and PVC is deleted.

The only way to change the status of pv back to bound(from terminating) is by editing etcd.see below links :
https://github.com/jianz/k8s-reset-terminating-pv
https://stackoverflow.com/questions/51585649/cancel-or-undo-deletion-of-persistent-volumes-in-kubernetes-cluster 


Alternatively since PV is blocked by PVC and pods we can get some time to take its backup and recreate PV(we will be backup and restore technique later)
So there is no easy way to revert deleting state of PV.


==============================
Scenario4:

>kubectl apply -f deployment_aks.yaml
>kubectl get deploy,po,pvc,pv
NAME                           READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nginx-deploy   0/2     2            0           12s

NAME                                READY   STATUS              RESTARTS   AGE
pod/nginx-deploy-57b4c9cf5f-n6qt7   0/1     ContainerCreating   0          12s
pod/nginx-deploy-57b4c9cf5f-xrks6   0/1     ContainerCreating   0          12s

NAME                          STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/mypvc   Bound    pvc-fb334bf3-738b-42dc-899e-b41b732bb39e   2Gi        RWX            azurefile      11s

NAME                                                        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM           STORAGECLASS   REASON   AGE
persistentvolume/pvc-fb334bf3-738b-42dc-899e-b41b732bb39e   2Gi        RWX            Delete           Bound    default/mypvc   azurefile               11s


Lets see how to recover if we accidentally delete PVC

delete PVC:
>kubectl delete  persistentvolumeclaim/mypvc  

Recovering from terminating PVC state:
a)you just need reconfigure the PV to "Retain"
b)allow the PVC to get deleted, then remove the previous claim from the PV. 
c)A new PVC can then be bound to it and all is well.


Lets change RECLAIM POLICY of PV so that if we delete PVC ,PV retains
>kubectl patch persistentvolume/pvc-fb334bf3-738b-42dc-899e-b41b732bb39e   -p '{"spec":{"persistentVolumeReclaimPolicy":"Retain"}}'

>kubectl get pvc,pv                                                                                                                
NAME                                     STATUS        VOLUME                                                      CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/mypvc   Terminating   pvc-fb334bf3-738b-42dc-899e-b41b732bb39e   2Gi            RWX                                 azurefile      12m

NAME                                                                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM           STORAGECLASS   REASON   AGE
persistentvolume/pvc-fb334bf3-738b-42dc-899e-b41b732bb39e   2Gi              RWX                      Retain                     Bound    default/mypvc   azurefile                                  12m


delete deployment your PVC will get removed and the PV (and the disk it references!) will be left intact:
>kubectl delete deployment.apps/nginx-deploy 

>kubectl get deploy,po,pvc,pv                                                                                                      
NAME                                                                                     CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS     CLAIM           STORAGECLASS   REASON   AGE
persistentvolume/pvc-fb334bf3-738b-42dc-899e-b41b732bb39e   2Gi            RWX                      Retain                     Released   default/mypvc   azurefile               15m

Edit the PV:
>kubectl edit pv persistentvolume/pvc-fb334bf3-738b-42dc-899e-b41b732bb39e
	
In the editor, remove the entire "claimRef" section. Remove all of the lines from (and including) "claimRef:" until the next tag with the same indentation level. The lines to remove should look more or less like this:
      claimRef:
        apiVersion: v1
        kind: PersistentVolumeClaim
        name: my-app-pvc-my-app-0
        namespace: default
        resourceVersion: "1234567"
        uid: 12345678-1234-1234-1234-1234567890ab
Save the changes and close the editor. Check the status of the PV and it should now show "Available".

Now you can re-create your PVC exactly as you originally did. That should then find the now "Available" PV and bind itself to it. 

>kubectl apply -f deployment_aks.yaml

>kubectl get deploy,po,pvc,pv                                             
NAME                           READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nginx-deploy   2/2     2            2           33s

NAME                                READY   STATUS    RESTARTS   AGE
pod/nginx-deploy-57b4c9cf5f-4j658   1/1     Running   0          33s
pod/nginx-deploy-57b4c9cf5f-rxd8f   1/1     Running   0          33s

NAME                                    STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/mypvc   Bound    pvc-fb334bf3-738b-42dc-899e-b41b732bb39e   2Gi        RWX            azurefile      32s

NAME                                                                                    CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM           STORAGECLASS   REASON   AGE
persistentvolume/pvc-fb334bf3-738b-42dc-899e-b41b732bb39e   2Gi           RWX                      Retain                      Bound    default/mypvc   azurefile                                 21m

inside and pods's  /usr/share/nginx/html location we can access old files of PV